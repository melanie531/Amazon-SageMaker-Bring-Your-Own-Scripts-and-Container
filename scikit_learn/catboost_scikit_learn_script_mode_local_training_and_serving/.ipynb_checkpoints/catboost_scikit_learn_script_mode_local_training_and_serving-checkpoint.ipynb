{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b248502c",
   "metadata": {},
   "source": [
    "## CatBoost Scikit Learn Script Mode Local Training and Serving \n",
    "\n",
    "This is a sample Python program that trains a simple CatBoost model using SageMaker scikit-learn Docker image, and then performs inference. This implementation will work on your *local computer* or in the *AWS Cloud*.\n",
    "\n",
    "#### Prerequisites:\n",
    "1. Install required Python packages:\n",
    "   `pip install -r requirements.txt`\n",
    "2. Docker Desktop installed and running on your computer:\n",
    "   `docker ps`\n",
    "3. You should have AWS credentials configured on your local machine in order to be able to pull the docker image from ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb03c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from sagemaker.predictor import csv_serializer\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful SageMaker variables\n",
    "try:\n",
    "    # You're using a SageMaker notebook\n",
    "    sess = sagemaker.Session()\n",
    "    bucket = sess.default_bucket()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    # You're using a notebook somewhere else\n",
    "    print(\"Setting role and SageMaker session manually...\")\n",
    "    \n",
    "    #please change the bucket, region and iam role as needed\n",
    "    bucket = \"catboost-demo\" \n",
    "    region = \"us-west-2\"\n",
    "\n",
    "    iam = boto3.client(\"iam\")\n",
    "    sagemaker_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "    sagemaker_execution_role_name = (\n",
    "        \"AmazonSageMaker-ExecutionRole-20200101T000001\"  # Change this to your role name\n",
    "    )\n",
    "    role = iam.get_role(RoleName=sagemaker_execution_role_name)[\"Role\"][\"Arn\"]\n",
    "    boto3.setup_default_session(region_name=region, profile_name=\"default\")\n",
    "    sess = sagemaker.Session(sagemaker_client=sagemaker_client, default_bucket=bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe1313",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "Download training and eval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_train = './data/train/boston_train.csv'\n",
    "local_validation = './data/validation/boston_validation.csv'\n",
    "local_test = './data/test/boston_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('./data/train/boston_train.csv') and \\\n",
    "        os.path.isfile('./data/validation/boston_validation.csv') and \\\n",
    "        os.path.isfile('./data/test/boston_test.csv'):\n",
    "    print('Training dataset exist. Skipping Download')\n",
    "else:\n",
    "    print('Downloading training dataset')\n",
    "\n",
    "    os.makedirs(\"./data\", exist_ok=True)\n",
    "    os.makedirs(\"./data/train\", exist_ok=True)\n",
    "    os.makedirs(\"./data/validation\", exist_ok=True)\n",
    "    os.makedirs(\"./data/test\", exist_ok=True)\n",
    "\n",
    "    data = load_boston()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.25, random_state=45)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=45)\n",
    "\n",
    "    trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "    trainX['target'] = y_train\n",
    "\n",
    "    valX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "    valX['target'] = y_test\n",
    "\n",
    "    testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "\n",
    "    trainX.to_csv(local_train, header=None, index=False)\n",
    "    valX.to_csv(local_validation, header=None, index=False)\n",
    "    testX.to_csv(local_test, header=None, index=False)\n",
    "\n",
    "    print('Downloading completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326c27d",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Starting model training using **local mode**. Note: if launching for the first time in local mode, container image download might take a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SKLearn estimator and call fit() to start the training\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point=\"catboost_train_deploy.py\",\n",
    "    source_dir='code',\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=\"local\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "train_location = 'file://' + local_train\n",
    "validation_location = 'file://' + local_validation\n",
    "\n",
    "sklearn.fit({'train': train_location, 'validation': validation_location})\n",
    "print('Completed model training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb2241b",
   "metadata": {},
   "source": [
    "## Deploying trained model in local instance\n",
    "We can also deploy the trained model and perform invocation against the local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf5af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Deploying endpoint in local mode')\n",
    "predictor = sklearn.deploy(1, 'local', serializer=csv_serializer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3285b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(local_test, 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "predictions = predictor.predict(payload)\n",
    "print('predictions: {}'.format(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45560438",
   "metadata": {},
   "source": [
    "## Clear up resources\n",
    "Delete the endpoint deployed in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f03c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f4ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
